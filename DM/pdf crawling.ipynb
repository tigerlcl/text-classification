{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datago Quiz \n",
    "\n",
    "- Editor: Tiger Li 李昌伦\n",
    "- Date: Jun 15 2019\n",
    "- 环境: Python 3.6, Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import os, re, requests, time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本爬取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬虫应对JS动态数据\n",
    "发现： 不能采用静态修改Base_URL的方式实现翻页爬虫，因为表格数据来自于javascript脚本，网页URL并不会发生变化\n",
    "\n",
    "方法： 使用selenium包提供的Chrome浏览器驱动，实现页面切换并用beautifulsoup解析页面html信息，最终转化为csv文件\n",
    "\n",
    "关于selenium介绍以及安装请点击[此处](https://selenium-python.readthedocs.io/)\n",
    "\n",
    "**selenium提供了显性/隐性等待策略，能够面对网络状况波动时，加载网页快慢的情况**，具体如何设置参考官方文档链接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化变量\n",
    "Base_URL = \"http://data.eastmoney.com/report/hyyb.html#dHA9MCZjZz0wJmR0PTQmcGFnZT0x\"\n",
    "PageLimit = 5\n",
    "current_page = 1\n",
    "\n",
    "# 自定义数据存储容器： topic：行业名称， title：标题，内容处为 pdf文档下载地址\n",
    "raw_table = {\"topic\":[],\"title\":[],\"PDF_url\":[]}\n",
    "\n",
    "# selenium chrome\n",
    "browser = webdriver.Chrome()\n",
    "browser.implicitly_wait(30)  # 隐性等待，最长等30秒\n",
    "browser.get(Base_URL)\n",
    "locator = (By.ID,\"PageCont\") \n",
    "\n",
    "try:\n",
    "    while current_page <= PageLimit:\n",
    "        soup = bs(browser.page_source, \"html.parser\")\n",
    "        table = soup.find('tbody')\n",
    "        # table infos on each page\n",
    "        for tr in table.find_all('tr'):\n",
    "            a = tr.find_all('a')\n",
    "            raw_table['topic'].append(a[0].text)\n",
    "            raw_table['title'].append(a[5].get('title'))\n",
    "            raw_table['PDF_url'].append(a[5].get('href'))\n",
    "        \n",
    "        # 每10页输出一次进度\n",
    "        if (current_page%10==0):\n",
    "            print(\" 已完成爬取页面 %d!\" % (current_page))\n",
    "        # 退出while循环\n",
    "        if current_page == PageLimit:\n",
    "            break\n",
    "        # 下一页\n",
    "        current_page += 1\n",
    "           \n",
    "        # 设置显性等待\n",
    "        browser.find_element_by_xpath(\"//a[contains(text(),'下一页')]\").click()\n",
    "        WebDriverWait(browser, 20).until(EC.presence_of_element_located(locator))\n",
    "        time.sleep(5)\n",
    "        \n",
    "finally:\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用Panda Dataframe查看爬取的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>PDF_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>通讯行业</td>\n",
       "      <td>创新与拼搏奠定中国设备商全球领先之路‚无惧波折、\"中华信\"借力5G继续进阶</td>\n",
       "      <td>/report/20190616/hy,APPJ6k1bLdVQIndustry.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>农牧饲渔</td>\n",
       "      <td>农林牧渔行业点评报告：三重因素助推种植走高‚2019农业板块种养齐涨</td>\n",
       "      <td>/report/20190616/hy,APPJ6kFacP7CIndustry.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>食品饮料</td>\n",
       "      <td>软饮料行业报告三部曲之一：瓶装水：润物无声‚立体透视水的生意经</td>\n",
       "      <td>/report/20190616/hy,APPJ6kFacP7DIndustry.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>食品饮料</td>\n",
       "      <td>食品饮料行业点评：非洲猪瘟疫苗最新动态点评</td>\n",
       "      <td>/report/20190616/hy,APPJ6kFacPS7Industry.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>食品饮料</td>\n",
       "      <td>农业&amp;食品周报：猪价近期小幅震荡‚产能维持加速下滑</td>\n",
       "      <td>/report/20190616/hy,APPJ6kFacPS8Industry.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  topic                                  title  \\\n",
       "0  通讯行业  创新与拼搏奠定中国设备商全球领先之路‚无惧波折、\"中华信\"借力5G继续进阶   \n",
       "1  农牧饲渔     农林牧渔行业点评报告：三重因素助推种植走高‚2019农业板块种养齐涨   \n",
       "2  食品饮料        软饮料行业报告三部曲之一：瓶装水：润物无声‚立体透视水的生意经   \n",
       "3  食品饮料                  食品饮料行业点评：非洲猪瘟疫苗最新动态点评   \n",
       "4  食品饮料              农业&食品周报：猪价近期小幅震荡‚产能维持加速下滑   \n",
       "\n",
       "                                         PDF_url  \n",
       "0  /report/20190616/hy,APPJ6k1bLdVQIndustry.html  \n",
       "1  /report/20190616/hy,APPJ6kFacP7CIndustry.html  \n",
       "2  /report/20190616/hy,APPJ6kFacP7DIndustry.html  \n",
       "3  /report/20190616/hy,APPJ6kFacPS7Industry.html  \n",
       "4  /report/20190616/hy,APPJ6kFacPS8Industry.html  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(raw_table)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('raw_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换超链接为PDF下载地址\n",
    "**此小节与下一小节 都可以利用multiprocessing进行加速处理，本质是对dataframe.apply函数的优化** [参考链接](https://stackoverflow.com/questions/26784164/pandas-multiprocessing-apply)\n",
    "\n",
    "最终我们获得了100页，共计5000条待处理的URL，下面的`get_pdf_url`函数会负责转换url为pdf下载地址，再次用到了requests+beautifulsoup解析\n",
    "\n",
    "CPU bound 提速明显"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用多进程加速\n",
    "def parallelize(data, func, num_of_processes=8):\n",
    "    data_split = np.array_split(data, num_of_processes)\n",
    "    pool = Pool(num_of_processes)\n",
    "    data = pd.concat(pool.map(func, data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "def run_on_subset(func, data_subset):\n",
    "    return data_subset.apply(func, axis=1)\n",
    "\n",
    "def parallelize_on_rows(data, func, num_of_processes=8):\n",
    "    return parallelize(data, partial(run_on_subset, func), num_of_processes)\n",
    "\n",
    "#### 以下两个函数 将会使用apply函数，并且利用multiprocessing加速 ###\n",
    "# 1. 定义函数用于 获取表格中每一行报告对应的pdf文件链接\n",
    "def get_pdf_url(x): \n",
    "    r = requests.get(\"http://data.eastmoney.com\" + x.PDF_url)\n",
    "    soup = bs(r.content, \"html.parser\",from_encoding=\"iso-8859-1\")\n",
    "    check = soup.select('a[href^=\"http://pdf\"]')\n",
    "    # 若找不到pdf链接，check会是空list\n",
    "    if check:\n",
    "        pdf_url = check[0].get('href')\n",
    "        return pdf_url\n",
    "    else:\n",
    "        # 输出无效pdf链接的行记录\n",
    "        print(\"no valid pdf_url at Row:\",x.name)\n",
    "        return 0\n",
    "\n",
    "# 2. 定义函数用于下载PDF文件\n",
    "def download_pdf(x):\n",
    "    # 创建行业对应文件夹\n",
    "    if x.pdf_url: \n",
    "        directory = \"dataset/\" + x.topic\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        # 部分文件名中包含/，会造成写入路径错误\n",
    "        path = directory + \"/%s.pdf\" % (x.title.replace(\"/\",\"_\"))     \n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            doc = requests.get(x.pdf_url)   \n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(doc.content)\n",
    "    else:\n",
    "        print(\"can't download PDF for invalid URL at Row: %d\"%(x.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('raw_table.csv') \n",
    "# 测试样本1\n",
    "test1 = df[4100:4200]\n",
    "# 以下两块代码为速度测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no valid pdf_url at Row: 4178\n",
      "CPU times: user 4.85 s, sys: 79.1 ms, total: 4.93 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%time cache1 = test1.apply(get_pdf_url, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no valid pdf_url at Row: 4178\n",
      "CPU times: user 23.6 ms, sys: 30 ms, total: 53.6 ms\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%time cache2 = parallelize_on_rows(test1, get_pdf_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no valid pdf_url at Row: 4419\n",
      "no valid pdf_url at Row: 909\n",
      "no valid pdf_url at Row: 4705\n",
      "no valid pdf_url at Row: 3579\n",
      "no valid pdf_url at Row: 3593\n",
      "no valid pdf_url at Row: 4767\n",
      "no valid pdf_url at Row: 2952\n",
      "no valid pdf_url at Row: 3668\n",
      "no valid pdf_url at Row: 1176\n",
      "no valid pdf_url at Row: 4178\n",
      "no valid pdf_url at Row: 1206\n",
      "no valid pdf_url at Row: 4314\n",
      "no valid pdf_url at Row: 4369\n",
      "CPU times: user 275 ms, sys: 105 ms, total: 379 ms\n",
      "Wall time: 6min 18s\n"
     ]
    }
   ],
   "source": [
    "# 需要一段时间\n",
    "%time cache3 = parallelize_on_rows(df, get_pdf_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**所以有13条记录无法获取有效的PDF链接**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      "topic      5000 non-null object\n",
      "title      5000 non-null object\n",
      "PDF_url    5000 non-null object\n",
      "pdf_url    5000 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df['pdf_url'] = cache3\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      "topic      5000 non-null object\n",
      "title      5000 non-null object\n",
      "pdf_url    5000 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_new = df.drop(columns=\"PDF_url\")\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载PDF文件\n",
    "\n",
    "考虑到最终会有100页，共5000份PDF文件需要下载，所以利用multiprocessing对df.apply函数加速\n",
    "\n",
    "下面两段代码分别是 加速以及不加速的测试， I/O bound所以提速可能不明显"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = pd.read_csv('output.csv')\n",
    "# 测试样本2\n",
    "test2 = df_new[1150:1250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't download PDF for invalid URL at Row: 1176\n",
      "can't download PDF for invalid URL at Row: 1206\n",
      "CPU times: user 1.75 s, sys: 778 ms, total: 2.53 s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%time cache1 = test2.apply(download_pdf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't download PDF for invalid URL at Row: 1176\n",
      "can't download PDF for invalid URL at Row: 1206\n",
      "CPU times: user 67.6 ms, sys: 47.4 ms, total: 115 ms\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%time cache2 = parallelize_on_rows(test2, download_pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't download PDF for invalid URL at Row: 4419\n",
      "can't download PDF for invalid URL at Row: 909\n",
      "can't download PDF for invalid URL at Row: 2952\n",
      "can't download PDF for invalid URL at Row: 1176\n",
      "can't download PDF for invalid URL at Row: 1206\n",
      "can't download PDF for invalid URL at Row: 4705\n",
      "can't download PDF for invalid URL at Row: 4178\n",
      "can't download PDF for invalid URL at Row: 3579\n",
      "can't download PDF for invalid URL at Row: 3593\n",
      "can't download PDF for invalid URL at Row: 4767\n",
      "can't download PDF for invalid URL at Row: 4178\n",
      "can't download PDF for invalid URL at Row: 3668\n",
      "can't download PDF for invalid URL at Row: 4314\n",
      "can't download PDF for invalid URL at Row: 4369\n",
      "CPU times: user 2.05 s, sys: 876 ms, total: 2.93 s\n",
      "Wall time: 20min 51s\n"
     ]
    }
   ],
   "source": [
    "#需要一段时间\n",
    "%time cache3 = parallelize_on_rows(df_new, download_pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查结果并存储csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共计下载了 4987份 PDF文件\n"
     ]
    }
   ],
   "source": [
    "num = df_new[df_new.pdf_url !=0].shape[0]\n",
    "print(\"共计下载了 %d份 PDF文件\"% num )\n",
    "df_new.to_csv(\"result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最终成型图\n",
    "<img src=\"img/img2.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本数据预处理\n",
    "1. 这里使用了[pdfminer3k](pdfminer: https://pypi.org/project/pdfminer3k/)帮助提取文本信息\n",
    "2. 生成了对应行业名称下的文本文档（.txt文件）\n",
    "3. 结果存放在了一个新的文件夹`text_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "import re,os\n",
    "import logging\n",
    "import jieba \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO\n",
    "from io import open\n",
    "\n",
    "# 需要预先安装包 \n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, process_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 文本预处理函数\n",
    "def pdf2text(path):\n",
    "    # 输入： PDF文件所在的路径\n",
    "    # 初始化\n",
    "    password = ''\n",
    "    pagenos = set()\n",
    "    maxpages = 0\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    laparams = LAParams()\n",
    "    \n",
    "    #读取PDF文档\n",
    "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    with open(path, 'rb') as file:\n",
    "        process_pdf(rsrcmgr, device, file, pagenos, maxpages=maxpages, password=password, check_extractable=True)\n",
    "\n",
    "    device.close()\n",
    "    content = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    \n",
    "    # 去除所有半角全角符号、字母、数字，只留中文。\n",
    "    lines = str(content).split('\\n')\n",
    "    text = ''.join(lines)\n",
    "    rule = re.compile(r\"[^\\u4e00-\\u9fa5]\")\n",
    "    text = rule.sub('',text)\n",
    "    # 输出纯中文文本 字符串\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46类: 输配电气/有色金属/公用事业/木业家具/船舶制造/电力行业/文化传媒/软件服务/汽车行业/煤炭采选/文教休闲/商业百货/电子元件/造纸印刷/多元金融/专用设备/食品饮料/电子信息/包装材料/家电行业/玻璃陶瓷/石油行业/医药制造/农牧饲渔/银行/机械行业/房地产/通讯行业/水泥建材/航天航空/旅游酒店/交运物流/装修装饰/交运设备/金属制品/保险/券商信托/工艺商品/环保工程/钢铁行业/纺织服装/综合行业/工程建设/材料行业/化工行业/医疗行业\n"
     ]
    }
   ],
   "source": [
    "# 生成所有行业标签\n",
    "labels = [f for f in os.listdir('dataset/') if not f.startswith('.')] # 避开.DS_store隐藏文件\n",
    "print(str(len(labels))+\"类: \"+ '/'.join(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输配电气 行业完成!\n",
      "有色金属 行业完成!\n",
      "公用事业 行业完成!\n",
      "木业家具 行业完成!\n",
      "船舶制造 行业完成!\n",
      "电力行业 行业完成!\n",
      "文化传媒 行业完成!\n",
      "软件服务 行业完成!\n",
      "汽车行业 行业完成!\n",
      "煤炭采选 行业完成!\n",
      "文教休闲 行业完成!\n",
      "商业百货 行业完成!\n",
      "电子元件 行业完成!\n",
      "造纸印刷 行业完成!\n",
      "多元金融 行业完成!\n",
      "专用设备 行业完成!\n",
      "食品饮料 行业完成!\n",
      "电子信息 行业完成!\n",
      "包装材料 行业完成!\n",
      "家电行业 行业完成!\n",
      "玻璃陶瓷 行业完成!\n",
      "石油行业 行业完成!\n",
      "医药制造 行业完成!\n",
      "农牧饲渔 行业完成!\n",
      "银行 行业完成!\n",
      "机械行业 行业完成!\n",
      "房地产 行业完成!\n",
      "通讯行业 行业完成!\n",
      "水泥建材 行业完成!\n",
      "航天航空 行业完成!\n",
      "旅游酒店 行业完成!\n",
      "交运物流 行业完成!\n",
      "装修装饰 行业完成!\n",
      "交运设备 行业完成!\n",
      "金属制品 行业完成!\n",
      "保险 行业完成!\n",
      "券商信托 行业完成!\n",
      "工艺商品 行业完成!\n",
      "环保工程 行业完成!\n",
      "钢铁行业 行业完成!\n",
      "纺织服装 行业完成!\n",
      "综合行业 行业完成!\n",
      "工程建设 行业完成!\n",
      "材料行业 行业完成!\n",
      "化工行业 行业完成!\n",
      "医疗行业 行业完成!\n",
      "共计345 PDF文档转换异常!\n"
     ]
    }
   ],
   "source": [
    "# ignore warnings\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "error_pdf = 0\n",
    "\n",
    "for label in labels:\n",
    "    # 基于每一类制作 词典\n",
    "    #if label == \"农牧饲渔\": # 中途暂停，已获得的小规模数据集\n",
    "    #    break\n",
    "    #label=\"木业家具\"\n",
    "    #print(\"%s 行业开始制作!\"% label)\n",
    "    pdf_dict = []\n",
    "    sub_dir = [f for f in os.listdir('dataset/'+ label) if not f.startswith('.')]\n",
    "    for pdf in sub_dir:\n",
    "        \n",
    "        # 写入到txt文件中， 涉及I/O 所以耗时较长\n",
    "        directory = 'txt_data/'+label\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            \n",
    "        text_path = directory +\"/\"+ pdf[:-4]+ '.txt'\n",
    "        if not os.path.exists(text_path):\n",
    "            try: \n",
    "                pdf_path = 'dataset/'+label +\"/\"+ pdf\n",
    "                text = pdf2text(pdf_path)\n",
    "                with open(text_path, 'w') as f:\n",
    "                    f.write(text)\n",
    "            # Exception Handler, 跳过此份问题PDF的读取\n",
    "            except Exception as e:\n",
    "                error_pdf += 1\n",
    "                #print(e)\n",
    "                continue\n",
    "                \n",
    "    print(\"%s 行业完成!\"% label)\n",
    "\n",
    "print(\"共计%d PDF文档转换异常!\" % error_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    4604\r\n"
     ]
    }
   ],
   "source": [
    "! ls txt_data/* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 效果图\n",
    "\n",
    "最终转化得到的文档总数 4604份\n",
    "\n",
    "<img src=\"img/img3.png\" width=\"50%\" height=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取新数据集\n",
    "读取数据集，完成分词并存储到dataframe中,此处包含中文分词处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/09/xvpww0g933qc13phh23w26mm0000gn/T/jieba.cache\n",
      "Loading model cost 0.616 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 1.37 s, total: 2min 47s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "frames = []\n",
    "categories =  [f for f in os.listdir('txt_data') if not f.startswith('.')]\n",
    "\n",
    "for cate in categories:\n",
    "    docs = [f for f in os.listdir('txt_data/'+ cate) if not f.startswith('.')]\n",
    "    txt_list = []\n",
    "    for doc in docs:\n",
    "        path = 'txt_data/'+ cate + \"/\" + doc\n",
    "        with open(path, \"rb\") as f:\n",
    "            text = f.read()\n",
    "            token = jieba.cut(text)\n",
    "            new_text = \" \".join(token)\n",
    "            txt_list.append(new_text)\n",
    "    #print(doc)\n",
    "    df_tmp = pd.DataFrame({\"label\": cate, \"text\": txt_list})\n",
    "    frames.append(df_tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "电子信息    301\n",
       "汽车行业    285\n",
       "文化传媒    280\n",
       "输配电气    277\n",
       "医药制造    236\n",
       "通讯行业    217\n",
       "食品饮料    211\n",
       "化工行业    202\n",
       "机械行业    183\n",
       "电子元件    168\n",
       "房地产     160\n",
       "航天航空    148\n",
       "银行      143\n",
       "券商信托    133\n",
       "有色金属    126\n",
       "钢铁行业    118\n",
       "商业百货    114\n",
       "造纸印刷    107\n",
       "旅游酒店    104\n",
       "公用事业     98\n",
       "纺织服装     94\n",
       "交运物流     94\n",
       "环保工程     93\n",
       "家电行业     91\n",
       "农牧饲渔     89\n",
       "水泥建材     70\n",
       "煤炭采选     61\n",
       "石油行业     56\n",
       "电力行业     48\n",
       "工程建设     39\n",
       "装修装饰     31\n",
       "多元金融     30\n",
       "保险       30\n",
       "材料行业     22\n",
       "文教休闲     19\n",
       "交运设备      7\n",
       "医疗行业      7\n",
       "金属制品      5\n",
       "木业家具      4\n",
       "玻璃陶瓷      2\n",
       "综合行业      2\n",
       "软件服务      2\n",
       "船舶制造      2\n",
       "专用设备      2\n",
       "工艺商品      1\n",
       "包装材料      1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat(frames, ignore_index=True)\n",
    "df_all.to_csv(\"label_text.csv\", index=False)\n",
    "df_all.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10折验证要求 由于测试集会被分组，所以每组至少要有一些数据，所以需要提前处理**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "电子信息    301\n",
       "汽车行业    285\n",
       "文化传媒    280\n",
       "输配电气    277\n",
       "医药制造    236\n",
       "通讯行业    217\n",
       "食品饮料    211\n",
       "化工行业    202\n",
       "机械行业    183\n",
       "电子元件    168\n",
       "房地产     160\n",
       "航天航空    148\n",
       "银行      143\n",
       "券商信托    133\n",
       "有色金属    126\n",
       "钢铁行业    118\n",
       "商业百货    114\n",
       "造纸印刷    107\n",
       "旅游酒店    104\n",
       "公用事业     98\n",
       "纺织服装     94\n",
       "交运物流     94\n",
       "环保工程     93\n",
       "家电行业     91\n",
       "农牧饲渔     89\n",
       "水泥建材     70\n",
       "煤炭采选     61\n",
       "石油行业     56\n",
       "电力行业     48\n",
       "工程建设     39\n",
       "装修装饰     31\n",
       "保险       30\n",
       "多元金融     30\n",
       "材料行业     22\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_all.groupby(\"label\").filter(lambda x: len(x) > 20)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4459 entries, 0 to 4505\n",
      "Data columns (total 2 columns):\n",
      "label    4459 non-null object\n",
      "text     4459 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入scikit-learn系列\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建与测试\n",
    "\n",
    "分散训练集与测试集, 考虑到每一个类下有不同数目的文档，设置`stratify`参数,依据标签y，按原数据y中各类比例，分配给train和test，使得train和test中各类数据的比例与原数据集一样。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['label'], random_state=42, test_size=0.2, stratify=df['label'])\n",
    "\n",
    "### 特征工程 ###\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# 准备用于 模型预测 输入\n",
    "X_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 285 ms, sys: 45.5 ms, total: 330 ms\n",
      "Wall time: 329 ms\n",
      "Accuracy : 0.4361\n"
     ]
    }
   ],
   "source": [
    "%time clf_NB = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf_NB.predict(X_test_counts) \n",
    "print(\"Accuracy : {:.4f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 52.1 ms, total: 15.5 s\n",
      "Wall time: 15.5 s\n",
      "Accuracy : 0.8733\n"
     ]
    }
   ],
   "source": [
    "%time clf_LR = LogisticRegression().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf_LR.predict(X_test_counts) \n",
    "print(\"Accuracy : {:.4f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.26 s, sys: 35.6 ms, total: 4.29 s\n",
      "Wall time: 4.29 s\n",
      "Accuracy : 0.8924\n"
     ]
    }
   ],
   "source": [
    "%time clf_SVM = LinearSVC().fit(X_train_tfidf, y_train)\n",
    "y_pred = clf_SVM.predict(X_test_counts) \n",
    "print(\"Accuracy : {:.4f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最高精度模型报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       交运物流       1.00      0.68      0.81        19\n",
      "         保险       0.86      1.00      0.92         6\n",
      "       公用事业       0.69      0.55      0.61        20\n",
      "       农牧饲渔       1.00      0.94      0.97        18\n",
      "       券商信托       0.84      0.96      0.90        27\n",
      "       化工行业       0.92      0.88      0.90        40\n",
      "       医药制造       1.00      0.98      0.99        47\n",
      "       商业百货       0.90      0.83      0.86        23\n",
      "       多元金融       0.00      0.00      0.00         6\n",
      "       家电行业       1.00      1.00      1.00        18\n",
      "       工程建设       0.67      0.50      0.57         8\n",
      "        房地产       1.00      0.97      0.98        32\n",
      "       文化传媒       0.96      0.98      0.97        56\n",
      "       旅游酒店       0.91      0.95      0.93        21\n",
      "       有色金属       1.00      0.96      0.98        25\n",
      "       机械行业       0.88      0.97      0.92        37\n",
      "       材料行业       0.00      0.00      0.00         4\n",
      "       水泥建材       0.87      0.93      0.90        14\n",
      "       汽车行业       0.89      0.98      0.93        57\n",
      "       煤炭采选       1.00      0.92      0.96        12\n",
      "       环保工程       0.77      0.89      0.83        19\n",
      "       电力行业       0.67      0.44      0.53         9\n",
      "       电子信息       0.74      0.87      0.80        60\n",
      "       电子元件       0.78      0.82      0.80        34\n",
      "       石油行业       0.67      0.73      0.70        11\n",
      "       纺织服装       0.95      1.00      0.97        19\n",
      "       航天航空       0.94      0.97      0.95        30\n",
      "       装修装饰       0.50      0.33      0.40         6\n",
      "       输配电气       0.89      0.87      0.88        55\n",
      "       通讯行业       0.91      0.91      0.91        43\n",
      "       造纸印刷       0.95      0.95      0.95        21\n",
      "       钢铁行业       0.96      1.00      0.98        24\n",
      "         银行       0.97      0.97      0.97        29\n",
      "       食品饮料       0.97      0.88      0.93        42\n",
      "\n",
      "avg / total       0.89      0.89      0.89       892\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_SVM.predict(X_test_counts) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K折-交叉验证\n",
    "\n",
    "K=10， 所实现的分类模型在 10-fold cross-validation 中的平均 F1 Score\n",
    "\n",
    "根据之前的三种Accuracy，选择最佳模型：`clf_SVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score 平均: 0.78 (+/- 0.02)\n",
      "CPU times: user 10.1 s, sys: 128 ms, total: 10.2 s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = cross_val_score(clf_SVM, count_vect.transform(df.text), df.label, cv=10, scoring='f1_macro', n_jobs=4)\n",
    "print(\"F1 Score 平均: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结束"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
